# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains marketing campaigns of a bank in which we can analyze the data , and build some predictive models to find new strategic ways to improve the future marketing campaigns, and target the right customers. The data is related with direct marketing campaigns of a banking institution. The classification goal is to predict if the client will subscribe to a term deposit (variable y).

I have used two different models as assigned by the project: 
1. Using the HyperDrive: Hyperparameters tuned are C (inverse regularization strength) and max_iter (maximum iterations allowed to converge). 
<a href ="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"> Link to Sklearn Logistic Regression. </a> Below is a snapshot of the best model selected using hyperdrive: <br/>
<img src= "./images/hyperdrive_info.png">
2. Using AutoML: The automl runs different models with different parameters automatically, and picks the best model. <a href ="https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml"> Link to AutoML documentation from Microsoft. </a> The best model selected is VotingEnsemble. Below is the snapshot of AutoML run: <br/>
<img src= "./images/AutoML_snapshot.png">

## Scikit-learn Pipeline
**Explaination of the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The dataset is created using tabular data factory function from blobstorage. Train.py is the training script- that will be called from sklearn estimator. Logistic Regression model is being defined in the script. The parameters and policy is defined by hyperdrive config function.The next step is to submit the run. Below is the architecture of how the pipeline is set up:<br/>
<img src= "./images/hyperdrive_flow.jpg">

**What are the benefits of the parameter sampler you chose?** <br/>
I have used random parameter sampling. In random sampling, hyperparameter values are randomly selected from the defined search space. It supports discrete and continuous hyperparameters. It also supports early termination of low-performance runs.

**What are the benefits of the early stopping policy you chose?** <br/>
I have selected bandit policy for early termination. It defines an early termination policy based on slack criteria, and a frequency and delay interval for evaluation.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
The best model being selected and registered by AutoML is Voting Ensemble. A voting ensemble is an ensemble machine learning model that combines the predictions from multiple other models. One important parameter to consider and make sure is the experiment timeout. The autoML can sometimes may stuck in long runs during model optimization and selection, therefore it is important to control this parameter. 

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**


## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
